{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "from theano import tensor\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import ShuffledScheme\n",
    "from fuel.datasets.iris import Iris\n",
    "from fuel.transformers import Mapping\n",
    "from blocks.bricks import Linear, Softmax, Logistic\n",
    "from blocks.bricks.cost import MisclassificationRate\n",
    "from blocks.initialization import Uniform, Constant\n",
    "from blocks.graph import ComputationGraph\n",
    "from blocks.algorithms import GradientDescent, Scale\n",
    "from blocks.main_loop import MainLoop\n",
    "from blocks.extensions import Timing, FinishAfter, Printing\n",
    "from blocks.extensions.monitoring import TrainingDataMonitoring\n",
    "from blocks.extras.extensions.plot import Plot\n",
    "from sklearn import metrics\n",
    "import os\n",
    "os.environ['FUEL_DATA_PATH'] = '/home/datasets/datasets1/fuel/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "nclasses = 3\n",
    "nfeatures = 4\n",
    "nhiddens = 5\n",
    "batch_size = 32\n",
    "nepochs = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Iris(which_sets=('all',))\n",
    "scheme = ShuffledScheme(examples=dataset.num_examples, batch_size=batch_size)\n",
    "stream = DataStream(dataset, iteration_scheme=scheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I = numpy.eye(nclasses, dtype=int)\n",
    "def one_hot(data):\n",
    "    return data[0], I[data[1].flatten()]\n",
    "stream = Mapping(stream, one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tensor.matrix('features')\n",
    "y = tensor.lmatrix('targets')\n",
    "linear = Linear(nfeatures, nclasses,\n",
    "                weights_init=Constant(0), biases_init=Constant(0))\n",
    "linear.initialize()\n",
    "linear_output = linear.apply(x)\n",
    "softmax = Softmax()\n",
    "y_hat = softmax.apply(linear_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = softmax.categorical_cross_entropy(y, linear_output).mean()\n",
    "error = MisclassificationRate().apply(y.nonzero()[1], y_hat)\n",
    "error.name = 'error'\n",
    "cost.name = 'cost'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg = ComputationGraph(cost)\n",
    "algorithm = GradientDescent(cost=cost, parameters=cg.parameters,\n",
    "                            step_rule=Scale(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "monitor = TrainingDataMonitoring([cost, error], prefix='tra', after_batch=True)\n",
    "extensions=[monitor, Printing(), Timing(), FinishAfter(after_n_epochs=nepochs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loop = MainLoop(algorithm, stream, extensions=extensions)\n",
    "loop.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loop.profile.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = theano.function([x], y_hat)\n",
    "x_vals, y_vals = stream.get_epoch_iterator().next()\n",
    "y_pred = predict(x_vals)\n",
    "metrics.accuracy_score(y_vals, y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Excercise:  Building more complex models\n",
    "Now, we are going to train a model with one more transformation (a MLP). Update the way to build the `y_hat` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_to_hidden = Linear(nfeatures, nhiddens,\n",
    "                weights_init=Uniform(width=0.01), biases_init=Constant(0))\n",
    "\n",
    "hidden_to_output = Linear(nhiddens, nclasses,\n",
    "                weights_init=Constant(0), biases_init=Constant(0))\n",
    "\n",
    "linear_to_hidden.initialize()\n",
    "hidden_to_output.initialize()\n",
    "\n",
    "h = Logistic().apply(linear_to_hidden.apply(x))\n",
    "linear_output = hidden_to_output.apply(h)\n",
    "softmax = Softmax()\n",
    "y_hat = softmax.apply(linear_output)\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run statements from [Cost](#cost)\n",
    "# Excercise: MLP with MNIST\n",
    "Modify the above code to train a MLP for MNIST dataset with Momentum update rule. Useful notes:\n",
    " - You should use the `Flatten` transfomer to preprocess [MNIST](http://fuel.readthedocs.org/en/latest/api/dataset.html?#module-fuel.datasets.mnist) dataset\n",
    " - Change the `Scale` update rule to the [Momentum](http://blocks.readthedocs.org/en/latest/api/algorithms.html?#blocks.algorithms.Momentum) rule and try values for `learning_rate` and `momentum` parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
