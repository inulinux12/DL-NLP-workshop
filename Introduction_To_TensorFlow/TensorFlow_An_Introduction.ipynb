{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TensorFlow: An Introduction *\n",
    "====================\n",
    "![MindLABLogo](images/mindlab-logo-simple.png \"MindLab\") \n",
    "![UNLogo](images/unal-logo.png \"MindLab\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** This notebook is heavily based on the TensorFlow documentation, particularly: **\n",
    "    \n",
    "   * https://www.tensorflow.org/versions/master/get_started/basic_usage.html \n",
    "   * https://www.tensorflow.org/versions/master/tutorials/seq2seq/index.html \n",
    "   * https://www.tensorflow.org/api_docs\n",
    "   * https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>To use TensorFlow we need to understand how TensorFlow:</h3>\n",
    "* Represents computations as graphs (Theano alike)\n",
    "* Executes graphs in the context of Sessions\n",
    "* Represents data as tensors\n",
    "* Maintains state with Variables\n",
    "* Uses feeds and fetches to get data into and out of arbitrary operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representing computations as graphs\n",
    "=========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simmilarly as happens with Theano, TensorFlow is built with the concept of variable dependence through a graph. \n",
    "* TensorFlow programs are usually structured into a construction phase, that assembles a graph, and an execution phase that uses a session to execute ops in the graph.\n",
    "* TensorFlow can be used from C, C++, and Python programs. It is presently much easier to use the Python library to assemble graphs, as it provides a large set of helper functions not available in the C and C++ libraries.\n",
    "* The session libraries have equivalent functionalities for the three languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "#\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix\n",
    "# multiplication.\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default graph now has three nodes: two constant() ops and one matmul() op. To actually multiply the matrices, and get the result of the multiplication, we must launch the graph in a session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launching the graph in a session\n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated.\n",
    "\n",
    "Launching follows construction. To launch a graph, create a Session object. Without arguments the session constructor launches the default graph.\n",
    "\n",
    "See the  [Session class](https://www.tensorflow.org/versions/master/api_docs/python/client.html#session-management \"Session\")  for the complete session API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "#Allocating just the GPU memory that we need\n",
    "#http://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "# Launch the default graph.\n",
    "sess = tf.Session()\n",
    "\n",
    "# To run the matmul op we call the session 'run()' method, passing 'product'\n",
    "# which represents the output of the matmul op.  This indicates to the call\n",
    "# that we want to get the output of the matmul op back.\n",
    "#\n",
    "# All inputs needed by the op are run automatically by the session.  They\n",
    "# typically are run in parallel.\n",
    "#\n",
    "# The call 'run(product)' thus causes the execution of threes ops in the\n",
    "# graph: the two constants and matmul.\n",
    "#\n",
    "# The output of the op is returned in 'result' as a numpy `ndarray` object.\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "# ==> If everithing goes well we should see [[ 12.]]\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of use in interactive Python environments, such as IPython you can instead use the InteractiveSession class, and the Tensor.eval() and Operation.run() methods. This avoids having to keep a variable holding the session.\n",
    "\n",
    "The only difference with a regular Session is that an InteractiveSession installs itself as the default session on construction. The methods Tensor.eval() and Operation.run() will use that session to run ops.\n",
    "\n",
    "This is convenient in interactive shells and IPython notebooks, as it avoids having to pass an explicit Session object to run ops.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Enter an interactive TensorFlow Session.\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# Initialize 'x' using the run() method of its initializer op.\n",
    "x.initializer.run()\n",
    "\n",
    "# Add an op to subtract 'a' from 'x'.  Run it and print the result\n",
    "sub = tf.sub(x, a)\n",
    "print(sub.eval())\n",
    "# ==> [-2. -1.]\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors and Variables\n",
    "===============================\n",
    "\n",
    "* *TensorFlow* programs use a <b>Tensor</b> data structure to represent all data -- only tensors are passed between operations in the computation graph. You can think of a TensorFlow tensor as an n-dimensional array or list. A tensor has a static type, a rank, and a shape.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Variable is a value that lives in TensorFlow's computation graph. It can be used and even modified by the computation. In machine learning applications, one generally has the model parameters be Variables.\n",
    "\n",
    "<b>Variables</b> maintain state across executions of the graph. The following example shows a variable serving as a simple counter. See the <a href=\"https://www.tensorflow.org/versions/master/api_docs/python/state_ops.html#variables-2\">Variable</a> class for more details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Create a Variable, that will be initialized to the scalar value 0.\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# Create an Op to add one to `state`.\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# Variables must be initialized by running an `init` Op after having\n",
    "# launched the graph.  We first have to add the `init` Op to the graph.\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph and run the ops.\n",
    "with tf.Session() as sess:\n",
    "  # Run the 'init' op\n",
    "  sess.run(init_op)\n",
    "  # Print the initial value of 'state'\n",
    "  print(sess.run(state))\n",
    "  # Run the op that updates 'state' and print 'state'.\n",
    "  for _ in range(3):\n",
    "    sess.run(update)\n",
    "    print(sess.run(state))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetches and Feeds \n",
    "=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "* The examples above introduce tensors into the computation graph by storing them in Constants and Variables. TensorFlow also provides a feed and fetch mechanisms for patching/retrieving a tensor directly into any operation in the graph.\n",
    "\n",
    "* A feed temporarily replaces the output of an operation with a tensor value. **You supply feed data as an argument to a run() call**. The feed is only used for the run call to which it is passed. The most common use case involves designating specific operations to be \"feed\" operations by using tf.placeholder() to create them\n",
    "* To fetch the outputs of operations, execute the graph with a run() call on the Session object and **pass in the tensors to retrieve**. In the previous example we fetched the single node state, but you can also fetch multiple tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "#Let's fetch something\n",
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.mul(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed])\n",
    "  print(result)\n",
    "\n",
    "# output:\n",
    "# [array([ 21.], dtype=float32), array([ 7.], dtype=float32)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 14.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#Lets feed something\n",
    "#A feed temporarily replaces the output of an operation with a tensor value. You supply feed data as an argument to a run() call. \n",
    "#The feed is only used for the run call to which it is passed. The most common use case involves designating specific operations to be \"feed\" operations by using tf.placeholder() to create them:\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.mul(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))\n",
    "\n",
    "# output:\n",
    "# [array([ 14.], dtype=float32)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Usage example: Fitting a line \n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from: https://www.tensorflow.org/versions/master/get_started/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(\"float32\")\n",
    "y_data = x_data * 0.1 + 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Minimize the mean squared errors.\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.00192705] [ 0.48994273]\n",
      "20 [ 0.05797241] [ 0.32253236]\n",
      "40 [ 0.08883978] [ 0.30598336]\n",
      "60 [ 0.09703647] [ 0.30158886]\n",
      "80 [ 0.09921306] [ 0.30042192]\n",
      "100 [ 0.09979101] [ 0.30011207]\n",
      "120 [ 0.0999445] [ 0.30002975]\n",
      "140 [ 0.09998529] [ 0.30000791]\n",
      "160 [ 0.09999609] [ 0.3000021]\n",
      "180 [ 0.09999897] [ 0.30000058]\n",
      "200 [ 0.09999974] [ 0.30000016]\n"
     ]
    }
   ],
   "source": [
    "# Before starting, initialize the variables.  We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Fit the line.\n",
    "for step in xrange(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Multiple GPU's\n",
    "========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to run TensorFlow on multiple GPUs, you can construct your model in a multi-tower fashion where each tower is assigned to a different GPU. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  44.   56.]\n",
      " [  98.  128.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creates a graph.\n",
    "c = []\n",
    "for d in ['/gpu:0', '/cpu:0']: # It was /gpu:2 but in HAL we have just 1 Titan X\n",
    "  with tf.device(d):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n",
    "    c.append(tf.matmul(a, b))\n",
    "with tf.device('/cpu:0'):\n",
    "  sum = tf.add_n(c)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print sess.run(sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence-to-Sequence Models in TensorFlow\n",
    "=============================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks can learn to model language, as already discussed in the RNN examples (there is also <a href=\"https://www.tensorflow.org/versions/master/tutorials/recurrent/index.html\">this one</a> of RNN in tensorflow). This raises an interesting question: could we condition the generated words on some input and generate a meaningful response? For example, could we train a neural network to translate from English to French? It turns out that the answer is yes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this example we will be able to build and train such a system end-to-end. We are assuming you have already installed via the pip package, have cloned the tensorflow git repository, and are in the root of the git tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This tutorial references the following files from the models/rnn folder in tensorflow instalation path (mine is on /home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/)\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>**File**</td> <td>**What's in it?**</td>\n",
    "<tr>\n",
    "        <td>seq2seq.py</td> <td>Library for building sequence-to-sequence models.</td>\n",
    "\n",
    "</tr>\n",
    "<tr>\n",
    "        <td>translate/data_utils.py</td> <td>Helper functions for preparing translation data.</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "        <td>translate/seq2seq_model.py</td> <td>Neural translation sequence-to-sequence model.</td>\n",
    "\n",
    "</tr>\n",
    "<tr>\n",
    "        <td>translate/translate.py</td> <td>Binary that trains and runs the translation model.</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "</tr>\n",
    "    \n",
    "</table>\n",
    "<a href=\"https://www.tensorflow.org/versions/master/tutorials/seq2seq/index.html\"> Complete tutorial </a><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/')\n",
    "import seq2seq_model\n",
    "import data_utils\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin                                                          \n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now let's define the flags for our parameters\n",
    "tf.app.flags.DEFINE_float(\"learning_rate\", 0.5, \"Learning rate.\")\n",
    "tf.app.flags.DEFINE_float(\"learning_rate_decay_factor\", 0.99,\n",
    "                          \"Learning rate decays by this much.\")\n",
    "tf.app.flags.DEFINE_float(\"max_gradient_norm\", 5.0,\n",
    "                          \"Clip gradients to this norm.\")\n",
    "tf.app.flags.DEFINE_integer(\"batch_size\", 64,\n",
    "                            \"Batch size to use during training.\")\n",
    "tf.app.flags.DEFINE_integer(\"size\", 1024, \"Size of each model layer.\")\n",
    "tf.app.flags.DEFINE_integer(\"num_layers\", 3, \"Number of layers in the model.\")\n",
    "tf.app.flags.DEFINE_integer(\"en_vocab_size\", 40000, \"English vocabulary size.\")\n",
    "tf.app.flags.DEFINE_integer(\"fr_vocab_size\", 40000, \"French vocabulary size.\")\n",
    "tf.app.flags.DEFINE_string(\"data_dir\", \"/home/datasets/datasets1/wmt_dataset/\", \"Data directory\")\n",
    "tf.app.flags.DEFINE_string(\"train_dir\", \"/home/jsotaloram/nlp/notebook/pretrained_model\", \"Training directory.\")\n",
    "tf.app.flags.DEFINE_integer(\"max_train_data_size\", 0,\n",
    "                            \"Limit on the size of training data (0: no limit).\")\n",
    "tf.app.flags.DEFINE_integer(\"steps_per_checkpoint\", 100,\n",
    "                            \"How many training steps to do per checkpoint.\")\n",
    "tf.app.flags.DEFINE_boolean(\"decode\", True,\n",
    "                            \"Set to True for interactive decoding.\")\n",
    "tf.app.flags.DEFINE_boolean(\"self_test\", False,\n",
    "                            \"Run a self-test if this is set to True.\")\n",
    "FLAGS = tf.app.flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use a number of buckets and pad to the closest one for efficiency.                                                    \n",
    "# See seq2seq_model.Seq2SeqModel for details of how they work.                                                             \n",
    "_buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(source_path, target_path, max_size=None):\n",
    "  \"\"\"Read data from source and target files and put into buckets.\n",
    "  Args:\n",
    "    source_path: path to the files with token-ids for the source language.\n",
    "    target_path: path to the file with token-ids for the target language;\n",
    "      it must be aligned with the source file: n-th line contains the desired\n",
    "      output for n-th line from the source_path.\n",
    "    max_size: maximum number of lines to read, all other will be ignored;\n",
    "      if 0 or None, data files will be read completely (no limit).\n",
    "  Returns:\n",
    "    data_set: a list of length len(_buckets); data_set[n] contains a list of\n",
    "      (source, target) pairs read from the provided data files that fit\n",
    "      into the n-th bucket, i.e., such that len(source) < _buckets[n][0] and\n",
    "      len(target) < _buckets[n][1]; source and target are lists of token-ids.\n",
    "  \"\"\"\n",
    "  data_set = [[] for _ in _buckets]\n",
    "  with gfile.GFile(source_path, mode=\"r\") as source_file:\n",
    "    with gfile.GFile(target_path, mode=\"r\") as target_file:\n",
    "      source, target = source_file.readline(), target_file.readline()\n",
    "      counter = 0\n",
    "      while source and target and (not max_size or counter < max_size):\n",
    "        counter += 1\n",
    "        if counter % 100000 == 0:\n",
    "          print(\"  reading data line %d\" % counter)\n",
    "          sys.stdout.flush()\n",
    "        source_ids = [int(x) for x in source.split()]\n",
    "        target_ids = [int(x) for x in target.split()]\n",
    "        target_ids.append(data_utils.EOS_ID)\n",
    "        for bucket_id, (source_size, target_size) in enumerate(_buckets):\n",
    "          if len(source_ids) < source_size and len(target_ids) < target_size:\n",
    "            data_set[bucket_id].append([source_ids, target_ids])\n",
    "            break\n",
    "        source, target = source_file.readline(), target_file.readline()\n",
    "  return data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(session, forward_only):\n",
    "  \"\"\"Create translation model and initialize or load parameters in session.\"\"\"\n",
    "  model = seq2seq_model.Seq2SeqModel(\n",
    "      FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,\n",
    "      FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,\n",
    "      FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,\n",
    "      forward_only=forward_only)\n",
    "  ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)\n",
    "  if ckpt and gfile.Exists(ckpt.model_checkpoint_path):\n",
    "    print(\"Reading model parameters from %s\" % ckpt.model_checkpoint_path)\n",
    "    model.saver.restore(session, ckpt.model_checkpoint_path)\n",
    "  else:\n",
    "    print(\"Created model with fresh parameters.\")\n",
    "    session.run(tf.initialize_all_variables())\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  \"\"\"Train a en->fr translation model using WMT data.\"\"\"\n",
    "  # Prepare WMT data.\n",
    "  print(\"Preparing WMT data in %s\" % FLAGS.data_dir)\n",
    "  en_train, fr_train, en_dev, fr_dev, _, _ = data_utils.prepare_wmt_data(\n",
    "      FLAGS.data_dir, FLAGS.en_vocab_size, FLAGS.fr_vocab_size)\n",
    "  with tf.Session() as sess:\n",
    "    # Create model.\n",
    "    print(\"Creating %d layers of %d units.\" % (FLAGS.num_layers, FLAGS.size))\n",
    "    model = create_model(sess, False)\n",
    "    # Read data into buckets and compute their sizes.\n",
    "    print (\"Reading development and training data (limit: %d).\"\n",
    "           % FLAGS.max_train_data_size)\n",
    "    dev_set = read_data(en_dev, fr_dev)\n",
    "    train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size)\n",
    "    train_bucket_sizes = [len(train_set[b]) for b in xrange(len(_buckets))]\n",
    "    train_total_size = float(sum(train_bucket_sizes))\n",
    "    # A bucket scale is a list of increasing numbers from 0 to 1 that we'll use\n",
    "    # to select a bucket. Length of [scale[i], scale[i+1]] is proportional to\n",
    "    # the size if i-th training bucket, as used later.\n",
    "    train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size\n",
    "                           for i in xrange(len(train_bucket_sizes))]\n",
    "    # This is the training loop.\n",
    "    step_time, loss = 0.0, 0.0\n",
    "    current_step = 0\n",
    "    previous_losses = []\n",
    "    while True:\n",
    "      # Choose a bucket according to data distribution. We pick a random number\n",
    "      # in [0, 1] and use the corresponding interval in train_buckets_scale.\n",
    "      random_number_01 = np.random.random_sample()\n",
    "      bucket_id = min([i for i in xrange(len(train_buckets_scale))\n",
    "                       if train_buckets_scale[i] > random_number_01])\n",
    "      # Get a batch and make a step.\n",
    "      start_time = time.time()\n",
    "      encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n",
    "          train_set, bucket_id)\n",
    "      _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,\n",
    "                                   target_weights, bucket_id, False)\n",
    "      step_time += (time.time() - start_time) / FLAGS.steps_per_checkpoint\n",
    "      loss += step_loss / FLAGS.steps_per_checkpoint\n",
    "      current_step += 1\n",
    "      # Once in a while, we save checkpoint, print statistics, and run evals.\n",
    "      if current_step % FLAGS.steps_per_checkpoint == 0:\n",
    "        # Print statistics for the previous epoch.\n",
    "        perplexity = math.exp(loss) if loss < 300 else float('inf')\n",
    "        print (\"global step %d learning rate %.4f step-time %.2f perplexity \"\n",
    "               \"%.2f\" % (model.global_step.eval(), model.learning_rate.eval(),\n",
    "                         step_time, perplexity))\n",
    "        # Decrease learning rate if no improvement was seen over last 3 times.\n",
    "        if len(previous_losses) > 2 and loss > max(previous_losses[-3:]):\n",
    "          sess.run(model.learning_rate_decay_op)\n",
    "        previous_losses.append(loss)\n",
    "        # Save checkpoint and zero timer and loss.\n",
    "        checkpoint_path = os.path.join(FLAGS.train_dir, \"translate.ckpt\")\n",
    "        model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n",
    "        step_time, loss = 0.0, 0.0\n",
    "        # Run evals on development set and print their perplexity.\n",
    "        for bucket_id in xrange(len(_buckets)):\n",
    "          encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n",
    "              dev_set, bucket_id)\n",
    "          _, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,\n",
    "                                       target_weights, bucket_id, True)\n",
    "          eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')\n",
    "          print(\"  eval: bucket %d perplexity %.2f\" % (bucket_id, eval_ppx))\n",
    "        sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode():\n",
    "  with tf.Session() as sess:\n",
    "    # Create model and load parameters.\n",
    "    model = create_model(sess, True)\n",
    "    model.batch_size = 1  # We decode one sentence at a time.\n",
    "    # Load vocabularies.\n",
    "    en_vocab_path = os.path.join(FLAGS.data_dir,\n",
    "                                 \"vocab%d.en\" % FLAGS.en_vocab_size)\n",
    "    fr_vocab_path = os.path.join(FLAGS.data_dir,\n",
    "                                 \"vocab%d.fr\" % FLAGS.fr_vocab_size)\n",
    "    en_vocab, _ = data_utils.initialize_vocabulary(en_vocab_path)\n",
    "    _, rev_fr_vocab = data_utils.initialize_vocabulary(fr_vocab_path)\n",
    "    # Decode from standard input.\n",
    "    sys.stdout.write(\"> \")\n",
    "    sys.stdout.flush()\n",
    "    sentence = sys.stdin.readline()\n",
    "    while sentence:\n",
    "      # Get token-ids for the input sentence.\n",
    "      token_ids = data_utils.sentence_to_token_ids(sentence, en_vocab)\n",
    "      # Which bucket does it belong to?\n",
    "      bucket_id = min([b for b in xrange(len(_buckets))\n",
    "                       if _buckets[b][0] > len(token_ids)])\n",
    "      # Get a 1-element batch to feed the sentence to the model.\n",
    "      encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n",
    "          {bucket_id: [(token_ids, [])]}, bucket_id)\n",
    "      # Get output logits for the sentence.\n",
    "      _, _, output_logits = model.step(sess, encoder_inputs, decoder_inputs,\n",
    "                                       target_weights, bucket_id, True)\n",
    "      # This is a greedy decoder - outputs are just argmaxes of output_logits.\n",
    "      outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n",
    "      # If there is an EOS symbol in outputs, cut them at that point.\n",
    "      if data_utils.EOS_ID in outputs:\n",
    "        outputs = outputs[:outputs.index(data_utils.EOS_ID)]\n",
    "      # Print out French sentence corresponding to outputs.\n",
    "      print(\" \".join([rev_fr_vocab[output] for output in outputs]))\n",
    "      print(\"> \", end=\"\")\n",
    "      sys.stdout.flush()\n",
    "      sentence = sys.stdin.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def self_test():\n",
    "  \"\"\"Test the translation model.\"\"\"\n",
    "  with tf.Session() as sess:\n",
    "    print(\"Self-test for neural translation model.\")\n",
    "    # Create model with vocabularies of 10, 2 small buckets, 2 layers of 32.\n",
    "    model = seq2seq_model.Seq2SeqModel(10, 10, [(3, 3), (6, 6)], 32, 2,\n",
    "                                       5.0, 32, 0.3, 0.99, num_samples=8)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    # Fake data set for both the (3, 3) and (6, 6) bucket.\n",
    "    data_set = ([([1, 1], [2, 2]), ([3, 3], [4]), ([5], [6])],\n",
    "                [([1, 1, 1, 1, 1], [2, 2, 2, 2, 2]), ([3, 3, 3], [5, 6])])\n",
    "    for _ in xrange(5):  # Train the fake model for 5 steps.\n",
    "      bucket_id = random.choice([0, 1])\n",
    "      encoder_inputs, decoder_inputs, target_weights = model.get_batch(\n",
    "          data_set, bucket_id)\n",
    "      model.step(sess, encoder_inputs, decoder_inputs, target_weights,\n",
    "                 bucket_id, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-test for neural translation model.\n"
     ]
    }
   ],
   "source": [
    "self_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  if FLAGS.self_test:\n",
    "    self_test()\n",
    "  elif FLAGS.decode:\n",
    "    decode()\n",
    "  else:\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate\n"
     ]
    }
   ],
   "source": [
    "cd /home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing WMT data in /home/datasets/datasets1/wmt_dataset/\n",
      "Creating 3 layers of 1024 units.\n",
      "Created model with fresh parameters.\n",
      "Reading development and training data (limit: 0).\n",
      "  reading data line 100000\n",
      "  reading data line 200000\n",
      "  reading data line 300000\n",
      "  reading data line 400000\n",
      "  reading data line 500000\n",
      "  reading data line 600000\n",
      "  reading data line 700000\n",
      "  reading data line 800000\n",
      "  reading data line 900000\n",
      "  reading data line 1000000\n",
      "  reading data line 1100000\n",
      "  reading data line 1200000\n",
      "  reading data line 1300000\n",
      "  reading data line 1400000\n",
      "  reading data line 1500000\n",
      "  reading data line 1600000\n",
      "  reading data line 1700000\n",
      "  reading data line 1800000\n",
      "  reading data line 1900000\n",
      "  reading data line 2000000\n",
      "  reading data line 2100000\n",
      "  reading data line 2200000\n",
      "  reading data line 2300000\n",
      "  reading data line 2400000\n",
      "  reading data line 2500000\n",
      "  reading data line 2600000\n",
      "  reading data line 2700000\n",
      "  reading data line 2800000\n",
      "  reading data line 2900000\n",
      "  reading data line 3000000\n",
      "  reading data line 3100000\n",
      "  reading data line 3200000\n",
      "  reading data line 3300000\n",
      "  reading data line 3400000\n",
      "  reading data line 3500000\n",
      "  reading data line 3600000\n",
      "  reading data line 3700000\n",
      "  reading data line 3800000\n",
      "  reading data line 3900000\n",
      "  reading data line 4000000\n",
      "  reading data line 4100000\n",
      "  reading data line 4200000\n",
      "  reading data line 4300000\n",
      "  reading data line 4400000\n",
      "  reading data line 4500000\n",
      "  reading data line 4600000\n",
      "  reading data line 4700000\n",
      "  reading data line 4800000\n",
      "  reading data line 4900000\n",
      "  reading data line 5000000\n",
      "  reading data line 5100000\n",
      "  reading data line 5200000\n",
      "  reading data line 5300000\n",
      "  reading data line 5400000\n",
      "  reading data line 5500000\n",
      "  reading data line 5600000\n",
      "  reading data line 5700000\n",
      "  reading data line 5800000\n",
      "  reading data line 5900000\n",
      "  reading data line 6000000\n",
      "  reading data line 6100000\n",
      "  reading data line 6200000\n",
      "  reading data line 6300000\n",
      "  reading data line 6400000\n",
      "  reading data line 6500000\n",
      "  reading data line 6600000\n",
      "  reading data line 6700000\n",
      "  reading data line 6800000\n",
      "  reading data line 6900000\n",
      "  reading data line 7000000\n",
      "  reading data line 7100000\n",
      "  reading data line 7200000\n",
      "  reading data line 7300000\n",
      "  reading data line 7400000\n",
      "  reading data line 7500000\n",
      "  reading data line 7600000\n",
      "  reading data line 7700000\n",
      "  reading data line 7800000\n",
      "  reading data line 7900000\n",
      "  reading data line 8000000\n",
      "  reading data line 8100000\n",
      "  reading data line 8200000\n",
      "  reading data line 8300000\n",
      "  reading data line 8400000\n",
      "  reading data line 8500000\n",
      "  reading data line 8600000\n",
      "  reading data line 8700000\n",
      "  reading data line 8800000\n",
      "  reading data line 8900000\n",
      "  reading data line 9000000\n",
      "  reading data line 9100000\n",
      "  reading data line 9200000\n",
      "  reading data line 9300000\n",
      "  reading data line 9400000\n",
      "  reading data line 9500000\n",
      "  reading data line 9600000\n",
      "  reading data line 9700000\n",
      "  reading data line 9800000\n",
      "  reading data line 9900000\n",
      "  reading data line 10000000\n",
      "  reading data line 10100000\n",
      "  reading data line 10200000\n",
      "  reading data line 10300000\n",
      "  reading data line 10400000\n",
      "  reading data line 10500000\n",
      "  reading data line 10600000\n",
      "  reading data line 10700000\n",
      "  reading data line 10800000\n",
      "  reading data line 10900000\n",
      "  reading data line 11000000\n",
      "  reading data line 11100000\n",
      "  reading data line 11200000\n",
      "  reading data line 11300000\n",
      "  reading data line 11400000\n",
      "  reading data line 11500000\n",
      "  reading data line 11600000\n",
      "  reading data line 11700000\n",
      "  reading data line 11800000\n",
      "  reading data line 11900000\n",
      "  reading data line 12000000\n",
      "  reading data line 12100000\n",
      "  reading data line 12200000\n",
      "  reading data line 12300000\n",
      "  reading data line 12400000\n",
      "  reading data line 12500000\n",
      "  reading data line 12600000\n",
      "  reading data line 12700000\n",
      "  reading data line 12800000\n",
      "  reading data line 12900000\n",
      "  reading data line 13000000\n",
      "  reading data line 13100000\n",
      "  reading data line 13200000\n",
      "  reading data line 13300000\n",
      "  reading data line 13400000\n",
      "  reading data line 13500000\n",
      "  reading data line 13600000\n",
      "  reading data line 13700000\n",
      "  reading data line 13800000\n",
      "  reading data line 13900000\n",
      "  reading data line 14000000\n",
      "  reading data line 14100000\n",
      "  reading data line 14200000\n",
      "  reading data line 14300000\n",
      "  reading data line 14400000\n",
      "  reading data line 14500000\n",
      "  reading data line 14600000\n",
      "  reading data line 14700000\n",
      "  reading data line 14800000\n",
      "  reading data line 14900000\n",
      "  reading data line 15000000\n",
      "  reading data line 15100000\n",
      "  reading data line 15200000\n",
      "  reading data line 15300000\n",
      "  reading data line 15400000\n",
      "  reading data line 15500000\n",
      "  reading data line 15600000\n",
      "  reading data line 15700000\n",
      "  reading data line 15800000\n",
      "  reading data line 15900000\n",
      "  reading data line 16000000\n",
      "  reading data line 16100000\n",
      "  reading data line 16200000\n",
      "  reading data line 16300000\n",
      "  reading data line 16400000\n",
      "  reading data line 16500000\n",
      "  reading data line 16600000\n",
      "  reading data line 16700000\n",
      "  reading data line 16800000\n",
      "  reading data line 16900000\n",
      "  reading data line 17000000\n",
      "  reading data line 17100000\n",
      "  reading data line 17200000\n",
      "  reading data line 17300000\n",
      "  reading data line 17400000\n",
      "  reading data line 17500000\n",
      "  reading data line 17600000\n",
      "  reading data line 17700000\n",
      "  reading data line 17800000\n",
      "  reading data line 17900000\n",
      "  reading data line 18000000\n",
      "  reading data line 18100000\n",
      "  reading data line 18200000\n",
      "  reading data line 18300000\n",
      "  reading data line 18400000\n",
      "  reading data line 18500000\n",
      "  reading data line 18600000\n",
      "  reading data line 18700000\n",
      "  reading data line 18800000\n",
      "  reading data line 18900000\n",
      "  reading data line 19000000\n",
      "  reading data line 19100000\n",
      "  reading data line 19200000\n",
      "  reading data line 19300000\n",
      "  reading data line 19400000\n",
      "  reading data line 19500000\n",
      "  reading data line 19600000\n",
      "  reading data line 19700000\n",
      "  reading data line 19800000\n",
      "  reading data line 19900000\n",
      "  reading data line 20000000\n",
      "  reading data line 20100000\n",
      "  reading data line 20200000\n",
      "  reading data line 20300000\n",
      "  reading data line 20400000\n",
      "  reading data line 20500000\n",
      "  reading data line 20600000\n",
      "  reading data line 20700000\n",
      "  reading data line 20800000\n",
      "  reading data line 20900000\n",
      "  reading data line 21000000\n",
      "  reading data line 21100000\n",
      "  reading data line 21200000\n",
      "  reading data line 21300000\n",
      "  reading data line 21400000\n",
      "  reading data line 21500000\n",
      "  reading data line 21600000\n",
      "  reading data line 21700000\n",
      "  reading data line 21800000\n",
      "  reading data line 21900000\n",
      "  reading data line 22000000\n",
      "  reading data line 22100000\n",
      "  reading data line 22200000\n",
      "  reading data line 22300000\n",
      "  reading data line 22400000\n",
      "  reading data line 22500000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shapedim { size: 2048 } dim { size: 2048 }\n\t [[Node: gradients_3/model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/Linear/concat, gradients_3/model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/add_grad/Reshape)]]\n\t [[Node: clip_by_global_norm_3/clip_by_global_norm_3/_15/_2999 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_200736_clip_by_global_norm_3/clip_by_global_norm_3/_15\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'gradients_3/model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/Linear/MatMul_grad/MatMul_1', defined at:\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/config/application.py\", line 574, in launch_instance\n    app.start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelapp.py\", line 373, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2981, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-fefabde1ae65>\", line 1, in <module>\n    get_ipython().magic(u'run translate.py --data_dir /home/datasets/datasets1/wmt_dataset/ --train_dir /home/jsotaloram/nlp/notebook/pretrained_model --en_vocab_size=40000 --fr_vocab_size=40000')\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2307, in magic\n    return self.run_line_magic(magic_name, magic_arg_s)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2228, in run_line_magic\n    result = fn(*args,**kwargs)\n  File \"<decorator-gen-58>\", line 2, in run\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magic.py\", line 193, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 738, in run\n    run()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 724, in run\n    exit_ignore=exit_ignore)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2637, in safe_execfile\n    self.compile if kw['shell_futures'] else None)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/utils/py3compat.py\", line 217, in execfile\n    builtin_mod.execfile(filename, *where)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 284, in <module>\n    tf.app.run()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 11, in run\n    sys.exit(main(sys.argv))\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 281, in main\n    train()\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 150, in train\n    model = create_model(sess, False)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 129, in create_model\n    forward_only=forward_only)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 164, in __init__\n    gradients = tf.gradients(self.losses[b], params)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 414, in gradients\n    in_grads = _AsList(grad_fn(op_wrapper, *out_grads))\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 365, in _MatMulGrad\n    math_ops.matmul(op.inputs[0], grad, transpose_a=True))\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 781, in matmul\n    name=name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 600, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/Linear/MatMul', defined at:\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 31 identical lines from previous traceback]\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 129, in create_model\n    forward_only=forward_only)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 155, in __init__\n    softmax_loss_function=softmax_loss_function)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 740, in model_with_buckets\n    bucket_decoder_inputs)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 154, in <lambda>\n    lambda x, y: seq2seq_f(x, y, False),\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 118, in seq2seq_f\n    feed_previous=do_decode)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 581, in embedding_attention_seq2seq\n    feed_previous)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 516, in embedding_attention_decoder\n    num_heads=num_heads, loop_function=loop_function)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 435, in attention_decoder\n    cell_output, new_state = cell(x, states[-1])\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/rnn_cell.py\", line 603, in __call__\n    cur_inp, new_state = cell(cur_inp, cur_state)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    180\u001b[0m           train_set, bucket_id)\n\u001b[0;32m    181\u001b[0m       _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,\n\u001b[1;32m--> 182\u001b[1;33m                                    target_weights, bucket_id, False)\n\u001b[0m\u001b[0;32m    183\u001b[0m       \u001b[0mstep_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_per_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstep_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_per_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.pyc\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, session, encoder_inputs, decoder_inputs, target_weights, bucket_id, forward_only)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0moutput_feed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m  \u001b[1;31m# Gradient norm, loss, no outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         raise errors._make_specific_exception(node_def, op, e.error_message,\n\u001b[1;32m--> 419\u001b[1;33m                                               e.code)\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shapedim { size: 2048 } dim { size: 2048 }\n\t [[Node: gradients_3/model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/Linear/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/Linear/concat, gradients_3/model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/add_grad/Reshape)]]\n\t [[Node: clip_by_global_norm_3/clip_by_global_norm_3/_15/_2999 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_200736_clip_by_global_norm_3/clip_by_global_norm_3/_15\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'gradients_3/model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/Linear/MatMul_grad/MatMul_1', defined at:\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/config/application.py\", line 574, in launch_instance\n    app.start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelapp.py\", line 373, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2981, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-fefabde1ae65>\", line 1, in <module>\n    get_ipython().magic(u'run translate.py --data_dir /home/datasets/datasets1/wmt_dataset/ --train_dir /home/jsotaloram/nlp/notebook/pretrained_model --en_vocab_size=40000 --fr_vocab_size=40000')\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2307, in magic\n    return self.run_line_magic(magic_name, magic_arg_s)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2228, in run_line_magic\n    result = fn(*args,**kwargs)\n  File \"<decorator-gen-58>\", line 2, in run\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magic.py\", line 193, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 738, in run\n    run()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 724, in run\n    exit_ignore=exit_ignore)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2637, in safe_execfile\n    self.compile if kw['shell_futures'] else None)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/utils/py3compat.py\", line 217, in execfile\n    builtin_mod.execfile(filename, *where)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 284, in <module>\n    tf.app.run()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 11, in run\n    sys.exit(main(sys.argv))\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 281, in main\n    train()\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 150, in train\n    model = create_model(sess, False)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 129, in create_model\n    forward_only=forward_only)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 164, in __init__\n    gradients = tf.gradients(self.losses[b], params)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 414, in gradients\n    in_grads = _AsList(grad_fn(op_wrapper, *out_grads))\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 365, in _MatMulGrad\n    math_ops.matmul(op.inputs[0], grad, transpose_a=True))\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 781, in matmul\n    name=name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 600, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_23/Cell0/GRUCell/Gates/Linear/MatMul', defined at:\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 31 identical lines from previous traceback]\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 129, in create_model\n    forward_only=forward_only)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 155, in __init__\n    softmax_loss_function=softmax_loss_function)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 740, in model_with_buckets\n    bucket_decoder_inputs)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 154, in <lambda>\n    lambda x, y: seq2seq_f(x, y, False),\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 118, in seq2seq_f\n    feed_previous=do_decode)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 581, in embedding_attention_seq2seq\n    feed_previous)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 516, in embedding_attention_decoder\n    num_heads=num_heads, loop_function=loop_function)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 435, in attention_decoder\n    cell_output, new_state = cell(x, states[-1])\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/rnn_cell.py\", line 603, in __call__\n    cur_inp, new_state = cell(cur_inp, cur_state)\n"
     ]
    }
   ],
   "source": [
    "%run translate.py --data_dir /home/datasets/datasets1/wmt_dataset/ --train_dir /home/jsotaloram/nlp/notebook/pretrained_model --en_vocab_size=40000 --fr_vocab_size=40000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing WMT data in /home/datasets/datasets1/wmt_dataset/\n",
      "Creating 3 layers of 1024 units.\n",
      "Created model with fresh parameters.\n",
      "Reading development and training data (limit: 1000000).\n",
      "  reading data line 100000\n",
      "  reading data line 200000\n",
      "  reading data line 300000\n",
      "  reading data line 400000\n",
      "  reading data line 500000\n",
      "  reading data line 600000\n",
      "  reading data line 700000\n",
      "  reading data line 800000\n",
      "  reading data line 900000\n",
      "  reading data line 1000000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shapedim { size: 64 } dim { size: 2048 }\n\t [[Node: model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_45/Cell1/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_45/Cell1/GRUCell/Gates/Linear/concat, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix)]]\n\t [[Node: global_norm_3/global_norm/_4563 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_227919_global_norm_3/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_45/Cell1/GRUCell/Gates/Linear/MatMul', defined at:\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/config/application.py\", line 574, in launch_instance\n    app.start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelapp.py\", line 373, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2981, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-fefabde1ae65>\", line 1, in <module>\n    get_ipython().magic(u'run translate.py --data_dir /home/datasets/datasets1/wmt_dataset/ --train_dir /home/jsotaloram/nlp/notebook/pretrained_model --en_vocab_size=40000 --fr_vocab_size=40000')\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2307, in magic\n    return self.run_line_magic(magic_name, magic_arg_s)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2228, in run_line_magic\n    result = fn(*args,**kwargs)\n  File \"<decorator-gen-58>\", line 2, in run\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magic.py\", line 193, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 738, in run\n    run()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 724, in run\n    exit_ignore=exit_ignore)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2637, in safe_execfile\n    self.compile if kw['shell_futures'] else None)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/utils/py3compat.py\", line 217, in execfile\n    builtin_mod.execfile(filename, *where)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 284, in <module>\n    tf.app.run()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 11, in run\n    sys.exit(main(sys.argv))\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 281, in main\n    train()\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 150, in train\n    model = create_model(sess, False)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 129, in create_model\n    forward_only=forward_only)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 155, in __init__\n    softmax_loss_function=softmax_loss_function)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 740, in model_with_buckets\n    bucket_decoder_inputs)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 154, in <lambda>\n    lambda x, y: seq2seq_f(x, y, False),\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 118, in seq2seq_f\n    feed_previous=do_decode)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 581, in embedding_attention_seq2seq\n    feed_previous)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 516, in embedding_attention_decoder\n    num_heads=num_heads, loop_function=loop_function)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 435, in attention_decoder\n    cell_output, new_state = cell(x, states[-1])\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/rnn_cell.py\", line 603, in __call__\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/rnn_cell.py\", line 120, in __call__\n    2 * self._num_units, True, 1.0))\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/linear.py\", line 44, in linear\n    res = tf.matmul(tf.concat(1, args), matrix)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 781, in matmul\n    name=name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 600, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    180\u001b[0m           train_set, bucket_id)\n\u001b[0;32m    181\u001b[0m       _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,\n\u001b[1;32m--> 182\u001b[1;33m                                    target_weights, bucket_id, False)\n\u001b[0m\u001b[0;32m    183\u001b[0m       \u001b[0mstep_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_per_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstep_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_per_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.pyc\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, session, encoder_inputs, decoder_inputs, target_weights, bucket_id, forward_only)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0moutput_feed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mforward_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m  \u001b[1;31m# Gradient norm, loss, no outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         raise errors._make_specific_exception(node_def, op, e.error_message,\n\u001b[1;32m--> 419\u001b[1;33m                                               e.code)\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shapedim { size: 64 } dim { size: 2048 }\n\t [[Node: model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_45/Cell1/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_45/Cell1/GRUCell/Gates/Linear/concat, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix)]]\n\t [[Node: global_norm_3/global_norm/_4563 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_227919_global_norm_3/global_norm\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'model_with_buckets/embedding_attention_seq2seq_3/embedding_attention_decoder/attention_decoder/MultiRNNCell_45/Cell1/GRUCell/Gates/Linear/MatMul', defined at:\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/config/application.py\", line 574, in launch_instance\n    app.start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelapp.py\", line 373, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2981, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-fefabde1ae65>\", line 1, in <module>\n    get_ipython().magic(u'run translate.py --data_dir /home/datasets/datasets1/wmt_dataset/ --train_dir /home/jsotaloram/nlp/notebook/pretrained_model --en_vocab_size=40000 --fr_vocab_size=40000')\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2307, in magic\n    return self.run_line_magic(magic_name, magic_arg_s)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2228, in run_line_magic\n    result = fn(*args,**kwargs)\n  File \"<decorator-gen-58>\", line 2, in run\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magic.py\", line 193, in <lambda>\n    call = lambda f, *a, **k: f(*a, **k)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 738, in run\n    run()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/magics/execution.py\", line 724, in run\n    exit_ignore=exit_ignore)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2637, in safe_execfile\n    self.compile if kw['shell_futures'] else None)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/IPython/utils/py3compat.py\", line 217, in execfile\n    builtin_mod.execfile(filename, *where)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 284, in <module>\n    tf.app.run()\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 11, in run\n    sys.exit(main(sys.argv))\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 281, in main\n    train()\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 150, in train\n    model = create_model(sess, False)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/translate.py\", line 129, in create_model\n    forward_only=forward_only)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 155, in __init__\n    softmax_loss_function=softmax_loss_function)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 740, in model_with_buckets\n    bucket_decoder_inputs)\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 154, in <lambda>\n    lambda x, y: seq2seq_f(x, y, False),\n  File \"/home/jsotaloram/nlp/tensorflow/tensorflow/models/rnn/translate/seq2seq_model.py\", line 118, in seq2seq_f\n    feed_previous=do_decode)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 581, in embedding_attention_seq2seq\n    feed_previous)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 516, in embedding_attention_decoder\n    num_heads=num_heads, loop_function=loop_function)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/seq2seq.py\", line 435, in attention_decoder\n    cell_output, new_state = cell(x, states[-1])\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/rnn_cell.py\", line 603, in __call__\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/rnn_cell.py\", line 120, in __call__\n    2 * self._num_units, True, 1.0))\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/models/rnn/linear.py\", line 44, in linear\n    res = tf.matmul(tf.concat(1, args), matrix)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 781, in matmul\n    name=name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 600, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "%run translate.py --data_dir /home/datasets/datasets1/wmt_dataset/ --train_dir /home/jsotaloram/nlp/notebook/pretrained_model --en_vocab_size=40000 --fr_vocab_size=40000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard: Visualizing Learning\n",
    "==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow programs, we've included a suite of visualization tools called TensorBoard. You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it. \n",
    "We'll run the MNIST tutorial with modifications to see some metrics on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jsotaloram/nlp/tensorflow/tensorflow/examples/tutorials/mnist\n"
     ]
    }
   ],
   "source": [
    "cd /home/jsotaloram/nlp/tensorflow/tensorflow/examples/tutorials/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All the model is this line\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To implement cross-entropy we need to first add a new placeholder to input the correct answers:\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9098\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now lets modify the code to put some summaries in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow.python.platform\n",
    "import input_data\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_boolean('fake_data', False, 'If true, uses fake data '\n",
    "                     'for unit testing.')\n",
    "flags.DEFINE_integer('max_steps', 1000, 'Number of steps to run trainer.')\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Create the model\n",
    "x = tf.placeholder('float', [None, 784], name='x-input')\n",
    "W = tf.Variable(tf.zeros([784, 10]), name='weights')\n",
    "b = tf.Variable(tf.zeros([10], name='bias'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a name scope to organize nodes in the graph visualizer\n",
    "with tf.name_scope('Wx_b'):\n",
    "  y = tf.nn.softmax(tf.matmul(x, W) + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Add summary ops to collect data\n",
    "_ = tf.histogram_summary('weights', W)\n",
    "_ = tf.histogram_summary('biases', b)\n",
    "_ = tf.histogram_summary('y', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder('float', [None, 10], name='y-input')\n",
    "# More name scopes will clean up the graph representation\n",
    "with tf.name_scope('xent'):\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "    _ = tf.scalar_summary('cross entropy', cross_entropy)\n",
    "\n",
    "with tf.name_scope('test'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "    _ = tf.scalar_summary('accuracy', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge all the summaries and write them out to /tmp/mnist_logs\n",
    "merged = tf.merge_all_summaries()\n",
    "writer = tf.train.SummaryWriter('/tmp/mnist_logs', sess.graph_def)\n",
    "tf.initialize_all_variables().run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--fake_data FAKE_DATA] [--nofake_data]\n",
      "                   [--max_steps MAX_STEPS] [--learning_rate LEARNING_RATE]\n",
      "__main__.py: error: unrecognized arguments: -f /home/jsotaloram/.ipython/profile_default/security/kernel-1783fdc4-3ea1-43ad-adee-0abf8d6d4ad5.json --profile-dir /home/jsotaloram/.ipython/profile_default\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "  # Train the model, and feed in test data and record summaries every 10 steps\n",
    "for i in range(FLAGS.max_steps):\n",
    "    if i % 10 == 0:  # Record summary data, and the accuracy\n",
    "        if FLAGS.fake_data:\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)\n",
    "            feed = {x: batch_xs, y_: batch_ys}\n",
    "        else:\n",
    "            feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "        result = sess.run([merged, accuracy], feed_dict=feed)\n",
    "        summary_str = result[0]\n",
    "        acc = result[1]\n",
    "        writer.add_summary(summary_str, i)\n",
    "        print('Accuracy at step %s: %s' % (i, acc))\n",
    "    else:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)\n",
    "        feed = {x: batch_xs, y_: batch_ys}\n",
    "        sess.run(train_step, feed_dict=feed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:IOError [Errno 2] No such file or directory: '/home/jsotaloram/nlp/tensorflow/tensorflow/examples/tutorials/mnist/tensorflow/tensorboard/TAG' on path /home/jsotaloram/nlp/tensorflow/tensorflow/examples/tutorials/mnist/tensorflow/tensorboard/TAG\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/tensorboard/tensorboard.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m   \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda/envs/mindlabenv/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mmain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jsotaloram/nlp/tensorflow/tensorflow/tensorboard/tensorboard.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresource_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_resource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tensorboard/TAG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TensorBoard is tag: %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "#The command to run tensorflow is \n",
    "%run /home/jsotaloram/nlp/tensorflow/tensorflow/tensorboard/tensorboard.py --logdir=/home/jsotaloram/nlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
